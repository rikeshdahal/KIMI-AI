<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Webcam Analysis</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background-color: #f0f0f0; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
        .video-container { position: relative; width: 100%; max-width: 640px; margin: 20px 0; }
        video, canvas { width: 100%; height: auto; border-radius: 4px; }
        .controls { margin: 20px 0; }
        button { padding: 10px 20px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
        button:hover { background-color: #0056b3; }
        input { padding: 8px; width: 60%; margin-left: 10px; border: 1px solid #ddd; border-radius: 4px; }
        .response { margin-top: 20px; padding: 15px; background-color: #f8f9fa; border-radius: 4px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>What's in my hand?</h1>
        <div class="video-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas" style="display: none;"></canvas>
        </div>
        <div class="controls">
            <button id="captureBtn">Capture Image</button>
            <input type="text" id="prompt" value="What is in my hand?" placeholder="Enter your prompt">
        </div>
        <div class="response">
            <h2>Response:</h2>
            <p id="responseText">Waiting for analysis...</p>
        </div>
    </div>

    <script>
        class GeminiVisionSystem {
            constructor() {
                this.video = document.getElementById('video');
                this.canvas = document.getElementById('canvas');
                this.captureBtn = document.getElementById('captureBtn');
                this.promptInput = document.getElementById('prompt');
                this.responseText = document.getElementById('responseText');
                this.context = this.canvas.getContext('2d');
                this.apiKey = 'AIzaSyAY4c_mp20hKDh1SAwDhsad4plD9AxRZVM'; // Replace with your actual key
                // Updated endpoint as of 2025 - verify with current Google AI docs
                this.apiEndpoint = 'https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent';
                
                this.initializeCamera();
                this.setupEventListeners();
            }

            async initializeCamera() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    this.video.srcObject = stream;
                } catch (error) {
                    console.error('Error accessing camera:', error);
                    this.responseText.textContent = 'Error: Unable to access camera';
                }
            }

            setupEventListeners() {
                this.captureBtn.addEventListener('click', () => this.captureAndAnalyze());
            }

            captureImage() {
                this.canvas.width = this.video.videoWidth;
                this.canvas.height = this.video.videoHeight;
                this.context.drawImage(this.video, 0, 0);
                return this.canvas.toDataURL('image/jpeg').split(',')[1];
            }

            async sendToGemini(imageBase64, prompt) {
                try {
                    const response = await fetch(`${this.apiEndpoint}?key=${this.apiKey}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            contents: [{
                                parts: [
                                    { text: prompt },
                                    {
                                        inline_data: {
                                            mime_type: 'image/jpeg',
                                            data: imageBase64
                                        }
                                    }
                                ]
                            }]
                        })
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }

                    const data = await response.json();
                    // Updated response parsing based on current API structure
                    return data.candidates[0].content.parts[0].text;
                } catch (error) {
                    console.error('Gemini API error:', error);
                    return `Error analyzing image with Gemini API: ${error.message}`;
                }
            }

            async captureAndAnalyze() {
                this.captureBtn.disabled = true;
                this.responseText.textContent = 'Analyzing...';
                
                const imageBase64 = this.captureImage();
                const prompt = this.promptInput.value;
                const response = await this.sendToGemini(imageBase64, prompt);
                
                this.responseText.textContent = response;
                this.captureBtn.disabled = false;
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            new GeminiVisionSystem();
        });
    </script>
</body>
</html>
